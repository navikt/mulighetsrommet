# Dette er en liste over anbefalte Alerts basert på https://doc.nais.io/observability/alerts/recommended_alerts/
---
apiVersion: "nais.io/v1"
kind: "Alert"
metadata:
  name: "mulighetsrommet-alarmer"
  namespace: team-mulighetsrommet
  labels:
    team: team-mulighetsrommet
spec:
  receivers:
    slack:
      channel: "#team-valp-feil"
  alerts:
    - alert: applikasjon nede
      expr: kube_deployment_status_replicas_available{deployment="mulighetsrommet-api"} == 0
      for: 2m
      description: "App {{ $labels.app }} er nede i namespace {{ $labels.kubernetes_namespace }}"
      action: "`kubectl describe pod -l app={{ $labels.app }} -n {{ $labels.namespace }}` for events, og `kubectl logs -l app={{ $labels.app }} -n {{ $labels.namespace }}` for logger"
    - alert: høy feilrate i logger
      expr: (100 * sum by (log_app, log_namespace) (rate(logd_messages_total{log_app="mulighetsrommet-api",log_level=~"Warning|Error"}[3m])) / sum by (log_app, log_namespace) (rate(logd_messages_total{log_app="mulighetsrommet-api"}[3m]))) > 10
      for: 3m
      action: "Sjekk loggene til app {{ $labels.log_app }} i namespace {{ $labels.log_namespace }}, for å se hvorfor det er så mye feil"
    - alert: feil i selftest # This alert uses a custom metric provided by https://github.com/navikt/common-java-modules
      expr: selftests_aggregate_result_status{app="mulighetsrommet-api"} > 0
      for: 1m
      action: "Sjekk app {{ $labels.app }} i namespace {{ $labels.kubernetes_namespace }} sine selftest for å se hva som er galt"
    - alert: Høy andel HTTP klientfeil (4xx responser)
      severity: danger
      expr: (100 * (sum by (app, route) (rate(ktor_http_server_requests_seconds_count{status=~"^5\\d\\d", kubernetes_namespace="team-mulighetsrommet", app="mulighetsrommet-api"}[3m])) / sum by (app, route) (rate(ktor_http_server_requests_seconds_count{kubernetes_namespace="team-mulighetsrommet", app="mulighetsrommet-api"}[3m])))) > 10
      for: 3m
      action: "Sjekk loggene til '{{ $labels.app }}' for å se hvorfor '{{ $labels.route }}' returnerer feilkoder"
    - alert: Høy andel HTTP klientfeil (4xx responser)
      severity: warning
      # Følgende endepunkt er unntatt fra denne alarmen:
      #  - /api/v1/tiltaksgjennomforinger/id/{arenaId}: endepunktet blir kalt av Komet for alle endringer på deltakere og vil resultere i mye 404
      #  - /api/v1/internal/arena/.*: endepunktene blir kalt fra arena-adapter og kan potensielt føre til en del 409-responser
      expr: (100 * (sum by (app, route) (rate(ktor_http_server_requests_seconds_count{status=~"^4\\d\\d", kubernetes_namespace="team-mulighetsrommet", app="mulighetsrommet-api", route!~'.*(/api/v1/tiltaksgjennomforinger/id/{arenaId}|/api/v1/internal/arena/.*)'}[3m])) / sum by (app, route) (rate(ktor_http_server_requests_seconds_count{kubernetes_namespace="team-mulighetsrommet", app="mulighetsrommet-api"}[3m])))) > 10
      for: 3m
      action: "Sjekk loggene til '{{ $labels.app }}' for å se hvorfor '{{ $labels.route }}' returnerer feilkoder"
